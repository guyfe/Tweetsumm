{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7167111,"sourceType":"datasetVersion","datasetId":4140417}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets rouge sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:00.149912Z","iopub.execute_input":"2023-12-18T18:31:00.150263Z","iopub.status.idle":"2023-12-18T18:31:00.611032Z","shell.execute_reply.started":"2023-12-18T18:31:00.150223Z","shell.execute_reply":"2023-12-18T18:31:00.609990Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea0d6040747a4e1fbbd098cc613e21a3"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers[torch]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport re\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:12.795022Z","iopub.execute_input":"2023-12-18T18:31:12.795430Z","iopub.status.idle":"2023-12-18T18:31:16.851597Z","shell.execute_reply.started":"2023-12-18T18:31:12.795390Z","shell.execute_reply":"2023-12-18T18:31:16.850538Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom transformers import AutoTokenizer, TrainingArguments, Trainer\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:16.852972Z","iopub.execute_input":"2023-12-18T18:31:16.853572Z","iopub.status.idle":"2023-12-18T18:31:29.178125Z","shell.execute_reply.started":"2023-12-18T18:31:16.853518Z","shell.execute_reply":"2023-12-18T18:31:29.177085Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"DF_PATH = '/kaggle/input/tweetsumfixed/tweets_df_new.csv'\ndf = pd.read_csv(DF_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:29.181439Z","iopub.execute_input":"2023-12-18T18:31:29.182576Z","iopub.status.idle":"2023-12-18T18:31:38.673776Z","shell.execute_reply.started":"2023-12-18T18:31:29.182512Z","shell.execute_reply":"2023-12-18T18:31:38.672950Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:38.675001Z","iopub.execute_input":"2023-12-18T18:31:38.675371Z","iopub.status.idle":"2023-12-18T18:31:38.695535Z","shell.execute_reply.started":"2023-12-18T18:31:38.675338Z","shell.execute_reply":"2023-12-18T18:31:38.694582Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                      text\n0        @115712 I understand. I would like to assist y...\n1            @sprintcare and how do you propose we do that\n2        @sprintcare I have sent several private messag...\n3        @115712 Please send us a Private Message so th...\n4                                       @sprintcare I did.\n...                                                    ...\n2800590  @823869 Hey, we'd be happy to look into this f...\n2800591  @115714 wtf!? Iâ€™ve been having really shitty s...\n2800592  @143549 @sprintcare You have to go to https://...\n2800593  @823870 Sounds delicious, Sarah! ðŸ˜‹ https://t.c...\n2800594  @AldiUK  warm sloe gin mince pies with ice cre...\n\n[2800595 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 I understand. I would like to assist y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare I have sent several private messag...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 Please send us a Private Message so th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare I did.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2800590</th>\n      <td>@823869 Hey, we'd be happy to look into this f...</td>\n    </tr>\n    <tr>\n      <th>2800591</th>\n      <td>@115714 wtf!? Iâ€™ve been having really shitty s...</td>\n    </tr>\n    <tr>\n      <th>2800592</th>\n      <td>@143549 @sprintcare You have to go to https://...</td>\n    </tr>\n    <tr>\n      <th>2800593</th>\n      <td>@823870 Sounds delicious, Sarah! ðŸ˜‹ https://t.c...</td>\n    </tr>\n    <tr>\n      <th>2800594</th>\n      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2800595 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‚Ð²Ð¸Ñ‚Ð¾Ð²","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    text = re.sub(r\"@(\\w){1,20}\", '', text)\n    text = re.sub(r\"http[\\w\\:\\/\\\\\\.]+\" ,'', text)\n    text = re.sub(r\"\\<[\\w]+\\>\" ,'', text)\n    return \" \".join(text.split())","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:38.698145Z","iopub.execute_input":"2023-12-18T18:31:38.698446Z","iopub.status.idle":"2023-12-18T18:31:38.703710Z","shell.execute_reply.started":"2023-12-18T18:31:38.698419Z","shell.execute_reply":"2023-12-18T18:31:38.702762Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(preprocess_text)\ndf = df.drop_duplicates().dropna()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:31:38.704994Z","iopub.execute_input":"2023-12-18T18:31:38.705331Z","iopub.status.idle":"2023-12-18T18:32:03.866686Z","shell.execute_reply.started":"2023-12-18T18:31:38.705302Z","shell.execute_reply":"2023-12-18T18:32:03.865715Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:32:03.870026Z","iopub.execute_input":"2023-12-18T18:32:03.870404Z","iopub.status.idle":"2023-12-18T18:32:04.506462Z","shell.execute_reply.started":"2023-12-18T18:32:03.870373Z","shell.execute_reply":"2023-12-18T18:32:04.505377Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### ÐœÐ¾Ð´ÐµÐ»ÑŒ","metadata":{}},{"cell_type":"code","source":"tokenizer_name = \"bert-base-uncased\"\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_name)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:52:34.153575Z","iopub.execute_input":"2023-12-18T18:52:34.153960Z","iopub.status.idle":"2023-12-18T18:52:34.406527Z","shell.execute_reply.started":"2023-12-18T18:52:34.153925Z","shell.execute_reply":"2023-12-18T18:52:34.405478Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(inputs):\n\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:52:36.116621Z","iopub.execute_input":"2023-12-18T18:52:36.117262Z","iopub.status.idle":"2023-12-18T18:52:36.122020Z","shell.execute_reply.started":"2023-12-18T18:52:36.117225Z","shell.execute_reply":"2023-12-18T18:52:36.120846Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"preprocess_function(['hello'])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:52:36.308893Z","iopub.execute_input":"2023-12-18T18:52:36.309795Z","iopub.status.idle":"2023-12-18T18:52:36.316674Z","shell.execute_reply.started":"2023-12-18T18:52:36.309758Z","shell.execute_reply":"2023-12-18T18:52:36.315596Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101, 7592, 102]], 'token_type_ids': [[0, 0, 0]], 'attention_mask': [[1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"class TorchDataset(Dataset):\n\n    def __init__(self, df):\n        self.df = df\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        return preprocess_function(self.df.loc[idx, 'text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:52:36.514063Z","iopub.execute_input":"2023-12-18T18:52:36.514433Z","iopub.status.idle":"2023-12-18T18:52:36.520011Z","shell.execute_reply.started":"2023-12-18T18:52:36.514398Z","shell.execute_reply":"2023-12-18T18:52:36.519000Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_dataset = TorchDataset(train_df)\ntest_dataset = TorchDataset(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:52:36.688116Z","iopub.execute_input":"2023-12-18T18:52:36.688500Z","iopub.status.idle":"2023-12-18T18:52:36.693006Z","shell.execute_reply.started":"2023-12-18T18:52:36.688466Z","shell.execute_reply":"2023-12-18T18:52:36.691991Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:52:37.686819Z","iopub.execute_input":"2023-12-18T18:52:37.687480Z","iopub.status.idle":"2023-12-18T18:53:02.372666Z","shell.execute_reply.started":"2023-12-18T18:52:37.687448Z","shell.execute_reply":"2023-12-18T18:53:02.371599Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c758d31ad22d4f8b81dc6f9624c4cf0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cba3df220924451acf61ebf168d069e"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (transform_act_fn): GELUActivation()\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ntokenizer.pad_token = '[PAD]'\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:53:02.374381Z","iopub.execute_input":"2023-12-18T18:53:02.374714Z","iopub.status.idle":"2023-12-18T18:53:02.380069Z","shell.execute_reply.started":"2023-12-18T18:53:02.374686Z","shell.execute_reply":"2023-12-18T18:53:02.379026Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"tweet-bert-uncased-2\",\n    save_strategy=\"steps\",\n    evaluation_strategy=\"steps\",\n    eval_steps=50000,\n    save_steps=50000,\n    learning_rate=1e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=True,\n    load_best_model_at_end=True,\n    report_to='none'\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=data_collator\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T18:53:02.381582Z","iopub.execute_input":"2023-12-18T18:53:02.382248Z","iopub.status.idle":"2023-12-19T05:59:46.705773Z","shell.execute_reply.started":"2023-12-18T18:53:02.382215Z","shell.execute_reply":"2023-12-19T05:59:46.704343Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='342329' max='754065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [342329/754065 11:06:40 < 13:21:50, 8.56 it/s, Epoch 1.36/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50000</td>\n      <td>1.671900</td>\n      <td>1.889556</td>\n    </tr>\n    <tr>\n      <td>100000</td>\n      <td>1.642200</td>\n      <td>1.880300</td>\n    </tr>\n    <tr>\n      <td>150000</td>\n      <td>1.661900</td>\n      <td>1.866874</td>\n    </tr>\n    <tr>\n      <td>200000</td>\n      <td>1.699900</td>\n      <td>1.854465</td>\n    </tr>\n    <tr>\n      <td>250000</td>\n      <td>1.622900</td>\n      <td>1.845560</td>\n    </tr>\n    <tr>\n      <td>300000</td>\n      <td>1.625600</td>\n      <td>1.827603</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 23\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet-bert-uncased-2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1865\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}